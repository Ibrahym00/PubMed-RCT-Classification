{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed RCT - Model Comparison\n",
    "\n",
    "This notebook compares the performance of the three models trained in the previous notebooks:\n",
    "1. Baseline (TF-IDF + Naive Bayes)\n",
    "2. Embeddings (GloVe)\n",
    "3. Deep Learning (Bi-LSTM)\n",
    "\n",
    "**Prerequisite:** Run notebooks 02, 03, and 04 first to generate the result files."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_dir = Path(\"../results\")\n",
    "\n",
    "def load_results(filename):\n",
    "    path = results_dir / filename\n",
    "    if path.exists():\n",
    "        with open(path) as f:\n",
    "            return json.load(f)\n",
    "    print(f\"File not found: {path}\")\n",
    "    return None\n",
    "\n",
    "baseline = load_results(\"baseline_results.json\")\n",
    "embeddings = load_results(\"embeddings_results.json\")\n",
    "bilstm = load_results(\"bilstm_results.json\")\n",
    "\n",
    "# Print loaded results\n",
    "for name, res in [(\"Baseline\", baseline), (\"Embeddings\", embeddings), (\"Bi-LSTM\", bilstm)]:\n",
    "    if res:\n",
    "        print(f\"{name}: accuracy = {res['test_accuracy']:.4f}\")\n",
    "    else:\n",
    "        print(f\"{name}: not available (run the corresponding notebook first)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rows = []\n",
    "if baseline:\n",
    "    rows.append({\"Model\": \"Baseline (TF-IDF + NB)\", \"Test Accuracy\": baseline[\"test_accuracy\"]})\n",
    "if embeddings:\n",
    "    rows.append({\"Model\": \"Embeddings (GloVe)\", \"Test Accuracy\": embeddings[\"test_accuracy\"]})\n",
    "if bilstm:\n",
    "    rows.append({\"Model\": \"Bi-LSTM\", \"Test Accuracy\": bilstm[\"test_accuracy\"]})\n",
    "\n",
    "if rows:\n",
    "    df = pd.DataFrame(rows).set_index(\"Model\")\n",
    "    print(df.to_string())\n",
    "else:\n",
    "    print(\"No results to compare. Run notebooks 02-04 first.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Chart"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if rows:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    colors = [\"#4c72b0\", \"#55a868\", \"#c44e52\"]\n",
    "    ax.bar(df.index, df[\"Test Accuracy\"], color=colors[:len(df)], edgecolor=\"black\")\n",
    "\n",
    "    for i, val in enumerate(df[\"Test Accuracy\"]):\n",
    "        ax.text(i, val + 0.005, f\"{val:.4f}\", ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Test Accuracy Comparison\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(axis=\"y\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Best model\n",
    "    best = df[\"Test Accuracy\"].idxmax()\n",
    "    print(f\"Best model: {best} ({df.loc[best, 'Test Accuracy']:.4f})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The comparison shows:\n",
    "- The **Baseline model** (TF-IDF + Naive Bayes) provides a simple and fast reference point.\n",
    "- **GloVe embeddings** capture word semantics and generally improve over the baseline.\n",
    "- The **Bi-LSTM** model captures sequential dependencies and tends to perform best.\n",
    "\n",
    "Possible improvements:\n",
    "- Use biomedical embeddings (BioWordVec, PubMedBERT)\n",
    "- Add positional features (sentence position in abstract)\n",
    "- Fine-tune a pre-trained transformer model (BERT, BioBERT)"
   ]
  }
 ]
}