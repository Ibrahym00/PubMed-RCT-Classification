{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed RCT - Baseline Model (TF-IDF + Naive Bayes)\n",
    "\n",
    "This notebook builds a baseline classifier using TF-IDF features and Multinomial Naive Bayes.\n",
    "\n",
    "**Approach:**\n",
    "- TF-IDF vectorization (unigrams + bigrams)\n",
    "- Multinomial Naive Bayes classifier\n",
    "- Sklearn Pipeline for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "id": "s3iksvvm1g",
   "source": "# ============================================================\n# Setup: auto-download dataset (works on Colab & locally)\n# ============================================================\nimport os\n\nDATA_DIR = \"../data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n\nif not os.path.exists(DATA_DIR):\n    print(\"Dataset not found locally. Downloading...\")\n    os.makedirs(\"../data\", exist_ok=True)\n    os.system(\"git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git ../data/pubmed-rct\")\n    print(\"Dataset downloaded!\")\nelse:\n    print(\"Dataset already available.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_pubmed_data(filepath):\n",
    "    \"\"\"Load and preprocess PubMed RCT data from a text file.\n",
    "    Returns a list of dicts with keys: target, text, line_number, total_lines.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    samples = []\n",
    "    abstract_lines = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"###\"):\n",
    "            abstract_lines = \"\"\n",
    "        elif line.isspace():\n",
    "            split = abstract_lines.splitlines()\n",
    "            for i, al in enumerate(split):\n",
    "                parts = al.split(\"\\t\")\n",
    "                if len(parts) == 2:\n",
    "                    samples.append({\n",
    "                        \"target\": parts[0],\n",
    "                        \"text\": parts[1].lower(),\n",
    "                        \"line_number\": i,\n",
    "                        \"total_lines\": len(split) - 1\n",
    "                    })\n",
    "        else:\n",
    "            abstract_lines += line\n",
    "\n",
    "    return samples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATA_DIR = \"../data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
    "CLASS_NAMES = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
    "\n",
    "train_samples = load_pubmed_data(os.path.join(DATA_DIR, \"train.txt\"))\n",
    "val_samples = load_pubmed_data(os.path.join(DATA_DIR, \"dev.txt\"))\n",
    "test_samples = load_pubmed_data(os.path.join(DATA_DIR, \"test.txt\"))\n",
    "\n",
    "train_df = pd.DataFrame(train_samples)\n",
    "val_df = pd.DataFrame(val_samples)\n",
    "test_df = pd.DataFrame(test_samples)\n",
    "\n",
    "X_train, y_train = train_df[\"text\"].to_numpy(), train_df[\"target\"].to_numpy()\n",
    "X_val, y_val = val_df[\"text\"].to_numpy(), val_df[\"target\"].to_numpy()\n",
    "X_test, y_test = test_df[\"text\"].to_numpy(), test_df[\"target\"].to_numpy()\n",
    "\n",
    "print(f\"Train: {len(X_train):,}  |  Val: {len(X_val):,}  |  Test: {len(X_test):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the Model\n",
    "\n",
    "We use a Pipeline that combines:\n",
    "1. **TfidfVectorizer**: converts text to TF-IDF vectors (unigrams + bigrams, max 10k features)\n",
    "2. **MultinomialNB**: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), max_features=10000,\n",
    "                               min_df=2, max_df=0.95, sublinear_tf=True)),\n",
    "    (\"clf\", MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Vocabulary size: {len(model.named_steps['tfidf'].vocabulary_):,}\")\n",
    "print(\"Training done.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Validation set\n",
    "val_preds = model.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, val_preds)\n",
    "print(f\"Validation accuracy: {val_acc*100:.2f}%\")\n",
    "print()\n",
    "print(classification_report(y_val, val_preds, target_names=CLASS_NAMES, digits=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test set\n",
    "test_preds = model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")\n",
    "print()\n",
    "print(classification_report(y_test, test_preds, target_names=CLASS_NAMES, digits=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, test_preds, labels=CLASS_NAMES)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title(\"Confusion Matrix - Baseline Model\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "errors = pd.DataFrame({\"text\": X_test, \"true\": y_test, \"pred\": test_preds})\n",
    "errors = errors[errors[\"true\"] != errors[\"pred\"]]\n",
    "\n",
    "print(f\"Total errors: {len(errors)} / {len(X_test)}  ({len(errors)/len(X_test)*100:.2f}%)\")\n",
    "print()\n",
    "print(\"Most frequent confusions:\")\n",
    "confusion_counts = errors.groupby([\"true\", \"pred\"]).size().sort_values(ascending=False)\n",
    "print(confusion_counts.head(5))\n",
    "print()\n",
    "print(\"Sample misclassified sentences:\")\n",
    "for _, row in errors.head(3).iterrows():\n",
    "    print(f\"  True: {row['true']}  |  Pred: {row['pred']}\")\n",
    "    print(f\"  Text: {row['text'][:100]}...\")\n",
    "    print()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    \"model_name\": \"Baseline (TF-IDF + Naive Bayes)\",\n",
    "    \"val_accuracy\": float(val_acc),\n",
    "    \"test_accuracy\": float(test_acc),\n",
    "}\n",
    "with open(\"../results/baseline_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved. Test accuracy = {test_acc*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}