{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed RCT - Deep Learning Model (Bidirectional LSTM)\n",
    "\n",
    "This notebook builds a Bi-LSTM model for sentence classification.\n",
    "\n",
    "**Architecture:**\n",
    "- TextVectorization layer\n",
    "- Trainable Embedding (128d)\n",
    "- Bidirectional LSTM (64 units)\n",
    "- Dense(64, ReLU) + Dropout(0.5)\n",
    "- Dense(5, softmax)\n",
    "\n",
    "**Callbacks:** EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, callbacks\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_pubmed_data(filepath):\n",
    "    \"\"\"Load and preprocess PubMed RCT data from a text file.\n",
    "    Returns a list of dicts with keys: target, text, line_number, total_lines.\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    samples = []\n",
    "    abstract_lines = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"###\"):\n",
    "            abstract_lines = \"\"\n",
    "        elif line.isspace():\n",
    "            split = abstract_lines.splitlines()\n",
    "            for i, al in enumerate(split):\n",
    "                parts = al.split(\"\\t\")\n",
    "                if len(parts) == 2:\n",
    "                    samples.append({\n",
    "                        \"target\": parts[0],\n",
    "                        \"text\": parts[1].lower(),\n",
    "                        \"line_number\": i,\n",
    "                        \"total_lines\": len(split) - 1\n",
    "                    })\n",
    "        else:\n",
    "            abstract_lines += line\n",
    "\n",
    "    return samples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "DATA_DIR = \"../data/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\"\n",
    "CLASS_NAMES = [\"BACKGROUND\", \"OBJECTIVE\", \"METHODS\", \"RESULTS\", \"CONCLUSIONS\"]\n",
    "MAX_LENGTH = 55\n",
    "\n",
    "train_df = pd.DataFrame(load_pubmed_data(os.path.join(DATA_DIR, \"train.txt\")))\n",
    "val_df = pd.DataFrame(load_pubmed_data(os.path.join(DATA_DIR, \"dev.txt\")))\n",
    "test_df = pd.DataFrame(load_pubmed_data(os.path.join(DATA_DIR, \"test.txt\")))\n",
    "\n",
    "train_sentences = train_df[\"text\"].to_numpy()\n",
    "val_sentences = val_df[\"text\"].to_numpy()\n",
    "test_sentences = test_df[\"text\"].to_numpy()\n",
    "\n",
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "train_labels = encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "val_labels = encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "test_labels = encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
    "\n",
    "print(f\"Train: {len(train_sentences)} | Val: {len(val_sentences)} | Test: {len(test_sentences)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max_tokens = 68000\n",
    "\n",
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_sequence_length=MAX_LENGTH\n",
    ")\n",
    "text_vectorizer.adapt(train_sentences)\n",
    "\n",
    "vocab = text_vectorizer.get_vocabulary()\n",
    "print(f\"Vocabulary size: {len(vocab)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "\n",
    "inputs = layers.Input(shape=[], dtype=\"string\")\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "x = layers.Embedding(input_dim=len(vocab), output_dim=embedding_dim, mask_zero=True)(x)\n",
    "x = layers.Bidirectional(layers.LSTM(lstm_units, recurrent_dropout=0.2))(x)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(len(CLASS_NAMES), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs, outputs, name=\"bilstm_model\")\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-7\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_sentences, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history.history[\"loss\"], label=\"Train\", marker=\"o\")\n",
    "ax1.plot(history.history[\"val_loss\"], label=\"Validation\", marker=\"s\")\n",
    "ax1.set_title(\"Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2.plot(history.history[\"accuracy\"], label=\"Train\", marker=\"o\")\n",
    "ax2.plot(history.history[\"val_accuracy\"], label=\"Validation\", marker=\"s\")\n",
    "ax2.set_title(\"Accuracy\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_loss, test_acc = model.evaluate(test_sentences, test_labels, verbose=0)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "preds = np.argmax(model.predict(test_sentences, verbose=0), axis=1)\n",
    "true = np.argmax(test_labels, axis=1)\n",
    "\n",
    "print()\n",
    "print(classification_report(true, preds, target_names=CLASS_NAMES))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(true, preds)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
    "plt.title(\"Confusion Matrix - Bi-LSTM Model\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    \"model_name\": \"Bidirectional LSTM\",\n",
    "    \"test_accuracy\": float(test_acc),\n",
    "    \"test_loss\": float(test_loss),\n",
    "}\n",
    "with open(\"../results/bilstm_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"Results saved. Test accuracy = {test_acc*100:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}